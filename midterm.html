<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Midterm - ADAM S LUCAS</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="midterm_files/libs/clipboard/clipboard.min.js"></script>
<script src="midterm_files/libs/quarto-html/quarto.js"></script>
<script src="midterm_files/libs/quarto-html/popper.min.js"></script>
<script src="midterm_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="midterm_files/libs/quarto-html/anchor.min.js"></script>
<link href="midterm_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="midterm_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="midterm_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="midterm_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="midterm_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Midterm - ADAM S LUCAS</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="computational-methods-for-fintech" class="level5">
<h5 class="anchored" data-anchor-id="computational-methods-for-fintech">Computational Methods For Fintech</h5>
<div style="page-break-after: always;"></div>
</section>
<section id="part-1" class="level2">
<h2 class="anchored" data-anchor-id="part-1">Part 1:</h2>
<section id="the-political-economy-of-financial-technology-and-innovation" class="level5">
<h5 class="anchored" data-anchor-id="the-political-economy-of-financial-technology-and-innovation">The Political Economy of Financial Technology and Innovation</h5>
</section>
<section id="the-market-order-of-catallaxy" class="level3">
<h3 class="anchored" data-anchor-id="the-market-order-of-catallaxy">1.1. The Market Order of Catallaxy</h3>
<section id="q1.-political-economy-vs-economic-science" class="level4">
<h4 class="anchored" data-anchor-id="q1.-political-economy-vs-economic-science">Q1. Political Economy vs Economic Science:</h4>
<section id="difference" class="level5">
<h5 class="anchored" data-anchor-id="difference">Difference:</h5>
<blockquote class="blockquote">
<p>I do believe as Buchanan believes that there is some connectedness of Political Economy and Economic Science. As he states, “Economists find themselves measuring social costs and social benefits..”. Our economy lives in a a transactional state, leaning towards the definition of economic science: “The systematic and evidence-based study of economic phenomena”, while a political economy is defined as: “interrelationships between political institutions, power structures, and economic systems.”. Nevertheless, in continuation of belief with Buchanan I find the need to lean towards a more true constitutional political economy, one that focuses on true economic concerns, future choices, and true arbitrage. Economic sciences can be a part of the political economy and if we want the economy to succeed I feel we must learn to include the sciences in the choices we make, and with the true analytics of the sciences we can learn to be political economists.</p>
</blockquote>
</section>
<section id="application-to-fintech-and-data-science" class="level5">
<h5 class="anchored" data-anchor-id="application-to-fintech-and-data-science">Application to FinTech and Data Science:</h5>
<blockquote class="blockquote">
<p>As FinTech becomes more prominent worldwide, the need to interpret, analyze, and predict the outcomes of any economy become more necessitated. The applications of Fintech can be established in a form that allows for mass computation of economical data with real time models, outcomes and predictions. With Data Science, the provication of such applications will become more prominent as well in the need of handling of economical data, in capacities that can only continue to grow. The world that Buchanan envisioned was one led by choice; with the combination of data science and financial technology, we can move beyond the simple idea of growth and political considerations, but truly move on to social implications that can shape the future economy in a more equitable, transparent, and beneficial society.</p>
</blockquote>
</section>
<section id="political-economy-of-financial-technology" class="level5">
<h5 class="anchored" data-anchor-id="political-economy-of-financial-technology">Political Economy of Financial Technology:</h5>
<blockquote class="blockquote">
<p>Does it make sense to speak of a <em>Political Economy of Financial Technology</em>? Oh, absolutely! The form in which politics have become such a key to the economy I find it necessary to speak of a Political Economy of Financial Technology, and I think it goes much deeper than a simple understanding of technology’s play on the finance of the political economy. I feel that Financial Technology can truly help establish the theory of catallactics more broadly; the increase of technology allows for a wider distribution of knowledge and a further reach to finance.</p>
</blockquote>
<blockquote class="blockquote">
<p>An establishment of a Political Economy of Financial Technology means for a greater structured growth of the financial technology and it’s application. Something I find intriguing about an economy, is the more an idea, or the application of the idea, becomes regulated, the larger the growth of the idea. If an order can be established for a political economy of financial technology the outcome could be catastrophically benefial for the growth of new forms of cooperation and collaboration worldwide.</p>
</blockquote>
<blockquote class="blockquote">
<p>However swell the idea is portrayed, there are quite a few details that require implementation in order to mitigate risks. In order to truly have a free and spontaneous market, the assurance that all individuals can possess, use and exchanges goods and services without the fear of interference, must be prominent. A free entry and exit for businesses must be established as well, this is crucial for permitting competition and preventing monopolies, thus allowing for innovation. And while there will be a <em>Political Economy</em> the actual government intervention must be limited. A political economy of financial technology could realistically find the right balance of regulation and facilation of market activity with these three key points, yet these strengths in the end are also the weaknesses of such an approach. The same need for the application of these ideas, is the same weakness that could simply destroy the idea of a catallaxy.</p>
</blockquote>
<blockquote class="blockquote">
<p>In simple terms, my position is to civilize society. I believe allowing for a Political Economy based on Financial Technology, is the way we should truly head towards in order to establish a more perfect union and create a true catallaxy of free movement and collaborated growth.</p>
</blockquote>
</section>
</section>
</section>
<section id="the-knowledge-problem-and-artificial-intelligence" class="level3">
<h3 class="anchored" data-anchor-id="the-knowledge-problem-and-artificial-intelligence">1.2 The Knowledge Problem and Artificial Intelligence</h3>
<section id="q2.-machina-economicus" class="level4">
<h4 class="anchored" data-anchor-id="q2.-machina-economicus">Q2. Machina Economicus</h4>
<blockquote class="blockquote">
<p>According to Parkes’ and Wellman’s it is my understanding that the Hayekian knowledge problem will continue to exist even with the development of more advanced AI agents. Part of the explanation that this paper gives is the explanation of where AI is getting it’s data; in essence with the knowledge problem, how can we assure that AI is getting <em>ALL</em> the data, and where is said data coming from, and can we truly trust it. Another key point analyzed in the paper is the logical understanding that humans possess, more specifically how does the AI know what to do without the logical or legal reasoning behind the action. So in summary, it is unlikely, at this time in life, that artificially intelligent machines can be relied upon to optimally allocate resources in the physical economy.</p>
</blockquote>
</section>
<section id="q3.-jordan-vs-parkes-and-wellman" class="level4">
<h4 class="anchored" data-anchor-id="q3.-jordan-vs-parkes-and-wellman">Q3. Jordan vs Parkes and Wellman</h4>
<blockquote class="blockquote">
<p>Parkes and Wellman, with their focus in “machina economicus”, believe that agents and their applications can behave rationally like “homo economicus”. Jordan on the other is more focused on the intersection between human capacity and information systems, somewhat making a system in itself. The correct discipline would be of an intelligent systems or maybe Data Systems Engineering.</p>
</blockquote>
<blockquote class="blockquote">
<p>While similar, both Jordan and Parkes and Wellman have the idea that the need for a combination of data, Parkes and Wellman looking more towards the understanding of an economy, whilst Jordan is looking at more techinical elements such as, statistics and computer science. Jordan also outlines understanding, safety, and realibility as key elements needing to develop a truly capable system. Another key element that Jordan discusses is the human utility and human preference, this leans towards an understanding system and not just a fully capable system.</p>
</blockquote>
</section>
<section id="q4.-hayeks-knowledge-problem-in-ai" class="level4">
<h4 class="anchored" data-anchor-id="q4.-hayeks-knowledge-problem-in-ai">Q4. Hayek’s Knowledge Problem in AI</h4>
<blockquote class="blockquote">
<p>Hayek’s Knowledge Problem applies to AI, 100%, yes! In my mind it is quite obvious the faults that AI currently contains, and this is considered innovation by the majority of the world. However, this does not explain why the knowledge problem applies. First, one man alone cannot create an AI system - a real system, not just a program - AI is built by teams, and not just technological teams. It is built by organizations that have no clue what the individual two cubicles down from them does, yet somehow the system, or application, gets built or in other terms, “Somehow, London is getting fed.”. Another key point to consider is the information that AI can currently obtain, however vast the database, the access, or the timeframe that AI can reach. There will always be more data, more time, and more information to be discovered. A good analogy for this that comes to mind is the tomb of the First Qin Emperor, we know where the tomb is, we know the majority of what is in the tomb, why it was built, etc.. Nevertheless, it is very undiscovered, like we have seen the opening, the terracotta army and that’s it. Nothing else. I wholeheartedly believe AI being in a very similar situation, the little pieces matter, so much so that we forget the little things in AI, we love that it can search the web and output text to us. But we forget that it has no clue what it is outputting without first an input. As Hayek states, (paraphrased because I can’t find the quote..), the solution is to let individuals use their own knowledge to make decisions. AI tries to be the central planner, but it doesn’t have all the pieces so it cannot solve everything that truly needs to be solved. AI lacks in many details and it is improving and continues to help the society grow, however, AI is not feeding London, we with AI are feeding London and I forsee it being that way for a long time. Even without all the information we can grow and build with AI, but we can’t be alone. That is why the Hayekian Knowledge Problem applies to AI.</p>
</blockquote>
<div style="page-break-after: always;"></div>
</section>
</section>
</section>
<section id="part-2-arbitrage-in-the-catallaxy" class="level2">
<h2 class="anchored" data-anchor-id="part-2-arbitrage-in-the-catallaxy">Part 2: Arbitrage in the Catallaxy</h2>
<section id="dutch-books-and-arbitrage" class="level3">
<h3 class="anchored" data-anchor-id="dutch-books-and-arbitrage">2.1 Dutch Books and Arbitrage</h3>
<section id="q5.-tootsie-roll-economy" class="level4">
<h4 class="anchored" data-anchor-id="q5.-tootsie-roll-economy">Q5. Tootsie Roll Economy</h4>
<blockquote class="blockquote">
<p>Using the example of the tootsie roll economy, we have a bag of tootsie rolls, you are walking through the market and decide you want to buy some tootsie rolls from the candy machine. However, the machine is sealed and you really don’t want to pay for a tootsie roll and end up with a chocolate. Thinking that cherry tootsie rolls are the most visible inside the candy machine, you assign a probability of 70% that the tootsie roll will be a cherry. By definition, the probability of the tootsie roll being chocolate is automatically calculated at 30%. A genius, by the name of Adam, sees you don’t want to purchase them in the case you get a tootsie roll you don’t want to eat. Adam then offers you a way to make money to recover your expenses; he offers you three separate bets:</p>
<ul>
<li><p>Bet 1: Adam bets $10 dollars that you will receive a cherry tootsie roll. You will accept, as your prior is 70%.</p></li>
<li><p>Bet 2: Adam bets $15 dollars that you will recieved a chocolate tootsie roll. You also accept this as favorable bet.</p></li>
<li><p>Bet 3: Adam bets $25 dollars that you will recieve either a chocolate tootsie roll or a cherry tootsie roll. As these are the only option you can get from the machine, you too accept this bet.</p></li>
</ul>
<p>Now you get your tootsie roll from the machine, it’s a chocolate. Well, darn, because those are disgusting, and more importantly you lost money, Adam, however, did not lose money, he made a nice profit of $10 dollars for doing absolute nothing. The financial outcome looks as follows: You paid Adam $25 dollars becuase of Bet 3, and Adam pays you $15 dollars because of Bet 2. You thus lost less money than you have by taking only one bet, but you were “Dutch Booked!”.</p>
</blockquote>
<blockquote class="blockquote">
<p>The bettaker, Adam, is cleary arbitraging the simple economy by setting up the 3 bets. Had it only been one or two bets, it would be near impossible to arbitrage. The real opportunity comes from your inconsistent subjective probability; by maintaining a disequilibrium in your probabily estimates, you allowed for Adam to come in and guarantee a profit through arbitrage. In order to impede Adam from making an arbitrage, your subjective probability would need to be consistent in order to avoid being “dutch booked.”</p>
</blockquote>
<blockquote class="blockquote">
<p>This does not give a derivation of Baye’s Rule. From what I understand from Skyrms paper, the probability today must be the same as the probabilty tomorrow. With our simple economy, there is no guarantee. In Baye’s simplified terms, your posterior may change now you have withdrawn a chocolate tootsie roll as Bayes is a mathematical formula for updating your prior. In Dutch Book terms, there is no specific updating of probabilities, you take your loss and move one. Once you’ve been dutched book, you now know the crook that robbed you so you won’t do it again, but your probabilities aren’t going to change near as much, if any.</p>
</blockquote>
</section>
<section id="q6.-neoclassical-finance-and-supply-and-demand-approach-of-neoclassical-economics" class="level4">
<h4 class="anchored" data-anchor-id="q6.-neoclassical-finance-and-supply-and-demand-approach-of-neoclassical-economics">Q6. Neoclassical Finance and Supply-and-Demand Approach of Neoclassical Economics</h4>
<blockquote class="blockquote">
<p>Ross’s understanding is intruiging in the aspect goes contrary to popular belief, which is why I too find it intriguing. Ross states, “the focus of finance is micro theoritic and the intuition of finance is the absence of arbitrage.” In agreement with Ross, I find these discoverings to be enlightening in vision that maybe the way are doing things is just because of some less-formal mathematical equation and less of what we truly beleive should happen in the financial markets. Ross brings insight that without these theories of finance in place we may be even more lost than we currently are. Nevertheless, it is most important to remember, that true efficient markets are efficient because of our intuition, the way things have always worked. To bring Hayek, and the knowledge probem, into perspective, London was fed without these mathematical equations and financial theories, and London is continue to be fed as well, with all theories and equations implented. Perhaps, we are truly lacking the knowledge of what is needed to have a efficient financial markt. Now to bring Ross back into this, maybe we need to step back and see how it worked before, solely on intuition, in order to see how we can truly arbitrate the catallaxy of the future.</p>
</blockquote>
<blockquote class="blockquote">
<p>A Dutch Book returns a net positive due to the disequilibrium in the subjective probabilities of the bettee. Ross states the following:</p>
<blockquote class="blockquote">
<p>“The forces of supply and demand have no meaning, since if the price is not the equilibrium price, then the difference between supply and demand is infinite. This is precisely what is meant by an arbitrage situation, and it is so qualitatively different from the economist’s usual picture of demand and supply as to require a different approach.”</p>
</blockquote>
<p>The dutch book allows for infinite possibilities above or below the equilibrium. Your demand in the previous tootsie roll economy, based on your subjective estimates allowed for a disequilibrium, allowed for Adam to place bets on either side of the scale to the infinity. Your desire for a cherry tootsie roll could never be portrayed by a linear line. Thus the approach of a dutch book can be beneficial in understand the true intuition of an individual; by moving the bets up and down Adam could discover to what extent you really want a tootsie roll, to what loss you will go in order to receive a tootsie, and also at what level of trust you hold your own personal intuition or prior.</p>
</blockquote>
</section>
</section>
<section id="operational-subjective-probability-and-statistics" class="level3">
<h3 class="anchored" data-anchor-id="operational-subjective-probability-and-statistics">2.2 Operational-Subjective Probability and statistics</h3>
<section id="q7.-arbitrage-choice-theory" class="level4">
<h4 class="anchored" data-anchor-id="q7.-arbitrage-choice-theory">Q7. Arbitrage Choice Theory</h4>
<blockquote class="blockquote">
<p>Simple answer: “PROBABILITY DOES NOT EXIST”, objectively, of course.</p>
<p>The key point to be discussed with the Arbitrage Choice Theory, and how it provides an operationally-subjective basis for a catallactic foundation of FinTech and Data Science, is the perception of de Finetti which states the following (paraphrased): probability is not an objective property of the world, but rather a personal degree of belief held by an individual. He also concluded that probability comes from an individuals willingness to bet on or against something. Which in simple terms, probability only exists when their is a price to be made, and that price depends wholly on the individual making the choice. A catallaxy is founded on the basis of the need to trade, barter and exchange. While Nau and McCardle don’t one-hundred percent agree with de Finetti definitions and terms, I conclude that the understanding is the same; Arbitrage Choice Theory extends the knowledge of choices under uncertainity - as long as choices are judged rationally and do not cause exploitations to the decision maker.</p>
</blockquote>
</section>
<section id="q8.-fundamental-theorem-of-statistical-inference" class="level4">
<h4 class="anchored" data-anchor-id="q8.-fundamental-theorem-of-statistical-inference">Q8. Fundamental Theorem of Statistical Inference</h4>
<blockquote class="blockquote">
<p>De Finetti approaches similarity to Baye’s Theorem is intriguing in itself. Poirier discusses that de Finettis approach is based on the idea of past observations being used to predict future observation. Bayes Theorem in essence is a copy of this approach in addition to having some form of prior belief. With these close connections established, the representation theorem lays important principles in the liklihoods, priors, and a large foundation of inductive reasoning in statistics and probability. Krep makes some key points, however, on the implication of frequentist theories tied into de Finetti’s theorem. In agreement with Krep, I feel that this is what makes the representation theorem so fundamental. The idea of implementing the true probability methods, found within Bayesian reasoning, and combining them with the consistency of key frequentist methods and properties, truly is fundamental to understanding of statistical inference.</p>
</blockquote>
<div style="page-break-after: always;"></div>
</section>
</section>
</section>
<section id="part-3-metallgesellschaft-and-the-economics-of-synthetic-storage" class="level2">
<h2 class="anchored" data-anchor-id="part-3-metallgesellschaft-and-the-economics-of-synthetic-storage">Part 3: Metallgesellschaft and the Economics of Synthetic Storage</h2>
<section id="futures-markets-and-hedging" class="level3">
<h3 class="anchored" data-anchor-id="futures-markets-and-hedging">3.1 Futures Markets and Hedging</h3>
<section id="q9.-arbitrage-principles" class="level4">
<h4 class="anchored" data-anchor-id="q9.-arbitrage-principles">Q9. Arbitrage principles</h4>
<blockquote class="blockquote">
<p><span class="math display">\[ F₀ &gt; S₀ \cdot e^{rT} \]</span></p>
<p>This implies an arbitrage opportunity if we are buying the stock at the current . Simply explained, the arbitrageur could buy the cheap forward contract and replicate it by short selling the assest. This is portrated by simple equation, where R equals return: <span class="math display">\[R =  F₀ - S₀ \cdot e^{rT} \]</span></p>
</blockquote>
<blockquote class="blockquote">
<p><span class="math display">\[ F₀ &lt; S₀ \cdot e^{rT} \]</span></p>
<p>Similar to the previous option, this could also imply an arbitrage opportunity if we are borrowing and buying the forward contract. Simply explained we would could arbitrate by buying the forward option of the stock at the lower price, and then knowingly wait for the spot price to match the forward price. Thus making a simple equation, where R equals return: <span class="math display">\[R =  S₀ \cdot e^{rT} - F₀ \]</span></p>
</blockquote>
<blockquote class="blockquote">
<p>In the case of the discrete dollar dividend payments. Dividends lower the forward price due to the fact that a forward contract does not earn dividends, thus the calculation needs to be done in order to account for the dividends lost while the contract is being held. The adjustment can be made by subtracting the dividend from the spot, thus lowering the total value of the spot price at time T. It would look something like this: <span class="math display">\[  F_0 = (S_0 - D_1) \cdot e^{rT_1} \]</span></p>
<p>In the case of a continuos dividend yield, it would be a similar equation yet again, but we will need to subtract the continous dividend yield from the risk free rate in the exponent, this is commonly expressed as q, and is in fraction form. <span class="math display">\[ F_0 = S_0 \cdot e^{(r-q)T} \]</span></p>
<blockquote class="blockquote">
<p>Both of these changes to the pricing equation can truly effect the arbitrage opportunities, or even just the return overall. By adding dividends, whether continous or a discrete dollar amount, the change associated can greatly impact the stock value. The implementation of dividends into the pricing model can help narrow down the true future value of the stock and can lead to arbitrage opportunites and accurate market adjustments.</p>
</blockquote>
</blockquote>
<blockquote class="blockquote">
<p>Commodies with storage costs change the pricing equation by differencing the “costs of carry”, as these are costs we subtract them from the pricing formula, thus making the equation look something like this: <span class="math display">\[F_0 = S_0 \cdot e^{rT} - cT\]</span> However, holding physical commodities also comes with some benefits, also known as the “convenience yield”, these benefits include advantages like the ability to sell at spike prices, keeping a business running, and being able to control the market. Since these are benefits, they are adding value to the asset thus requiring one more change to the equation, thus making the final equation look like so: <span class="math display">\[F=0 = S_0 \cdot e^{rT} + yT - cT\]</span> The costs of physically holding the commodite decrease the forward price, and the benefits increase the forward price.</p>
</blockquote>
<blockquote class="blockquote">
<p>In a normal market future prices are converging to spot prices at expiration due to delivery. This is consistent in order to limit the arbitrage opportunities. If futures prices were higher than the spot price, people would sell futures and buy the spot price. This in itself is brings the prices together, because of this action we know that spot prices and futures prices are accurate. If they didn’t become closer near maturity we would begin to lose accuracy and trust in the option. If spot and future prices did not converge at the maturity date we would have quite the problem. The main problem being the loss of arbitrage, if we know the prices are going to converge it becomes easy to arbitrate the market and buy low and sell high or viceversa. Without this convergence of the future price equalling the stock price, profits without risk would become prominent.</p>
</blockquote>
<blockquote class="blockquote">
<p>A change to the pricing formula would be quite simple, all that is needed is to account for the removal of the continued payments so we flip the formula to negative <span class="math display">\[F_0 = S_0 \cdot e^{-rT}\]</span> This is to indicate the instant payment that comes from purchasing the option at time = 0, or right now. The negative also removes the earnings that come from owning the asset, since the buyer has just paid for the option and has yet to receive the actual commodity.</p>
<p>This does happen in real life, an example that came to mind is farming. Farmers tend to predict what the season will be like ahead of time, and because of such they have to know what crops they will sell before they even start the seaoson. This then allows for arbitrage on multiple sides all on a prepaid forward contract. Farmer number 1 goes into a forward contract with the farmer number 2, selling 100 dollars worth of corn seeds, with the promise the farmer will give him 10 haybales for his cattle at the end of the year. Farmer number 2 then goes into a contract with neighbor Jimmy, where Jimmy gives him 110 dollars with the promise of 10 bushels of corn at the end of the season. None of the farmers, nor Jimmy know what the prices will be at the end of the harvest. Corn prices could go up which means Jimmy saves money and Farmer 2 loses money, or maybe the opposite and Jimmy still gets his corn, but at a very high price. This can be played in many different ways, and I am sure it is used all the time for tax purposes, getting businesses off the ground, or just sneaky financial purposes. When played correctly a prepaid forward contract could return a lot of value.</p>
</blockquote>
<div style="page-break-after: always;"></div>
</section>
<section id="q10.-data-with-crude-oil" class="level4">
<h4 class="anchored" data-anchor-id="q10.-data-with-crude-oil">Q10. Data with Crude Oil</h4>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.tsa.stattools <span class="im">import</span> adfuller, coint</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'WTI-Prices-1992-to-1993.csv'</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Levels"</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>adf_test <span class="op">=</span> adfuller(df[<span class="st">'Spot'</span>])</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'ADF Stat: </span><span class="sc">%f</span><span class="st">'</span> <span class="op">%</span> adf_test[<span class="dv">0</span>])</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>levels_p <span class="op">=</span> adf_test[<span class="dv">1</span>]</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'p_value: </span><span class="sc">%f</span><span class="st">'</span> <span class="op">%</span> levels_p)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">First Price Differences"</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>diff <span class="op">=</span> df[<span class="st">'Spot'</span>].diff()</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>adf_test <span class="op">=</span> adfuller(diff.dropna())</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'ADF Stat: </span><span class="sc">%f</span><span class="st">'</span> <span class="op">%</span> adf_test[<span class="dv">0</span>])</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>diff_p <span class="op">=</span> adf_test[<span class="dv">1</span>]</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'p_value: </span><span class="sc">%f</span><span class="st">'</span> <span class="op">%</span> diff_p)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Log Prices - Levels"</span>)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>log_prc <span class="op">=</span> np.log(df[<span class="st">'Spot'</span>])</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>adf_test <span class="op">=</span> adfuller(log_prc)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'ADF Stat: </span><span class="sc">%f</span><span class="st">'</span> <span class="op">%</span> adf_test[<span class="dv">0</span>])</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>log_levels_p <span class="op">=</span> adf_test[<span class="dv">1</span>]</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'p_value: </span><span class="sc">%f</span><span class="st">'</span> <span class="op">%</span> log_levels_p)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Log Prices - Differences"</span>)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>diff <span class="op">=</span> log_prc.diff().dropna()</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>adf_test <span class="op">=</span> adfuller(diff)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'ADF Stat: </span><span class="sc">%f</span><span class="st">'</span> <span class="op">%</span> adf_test[<span class="dv">0</span>])</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>log_diff_p <span class="op">=</span> adf_test[<span class="dv">1</span>]</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'p_value: </span><span class="sc">%f</span><span class="st">'</span> <span class="op">%</span> log_diff_p)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="co"># My results</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"""</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="st">Levels: Since the P Value is so high, I conclude that we fail to reject the null hypothesis of a unit root. In other words, the levels in this time series contain a unit root and are non-stationary.</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"""</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="st">First Price Differences: Since the P Value is 0 we can reject the null hyptothesis and I conclude the First Price Differences do not contain a unit root and are stationary time sets.  </span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"""</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="st">Log Levels: Even after changing to log the P Value stays high, this again means that we can fail to reject the null hyptothesis and I continue to conlude that the log levels containa unit root and are non-stationarity.</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"""  </span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="st">Log First Differences: P value still stays at 0 meaning we continue to strongly reject the null hypothesis. I also continue to conclude that the log of first differences does not contain a unit root and are stationary time sets.</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"""</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="st">For time series data it does not suprise me too much, with most time series data it is stochastic, however when we take differences in price levels, because of random walk and mean reversion I expect the difference to all make the data stationary.</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Time Series Plots</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TIME SERIES PLOTS:"</span>)</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Price levels</span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>plt.plot(df[<span class="st">'Spot'</span>])</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Levels'</span>)</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Prices'</span>)</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="co"># First differences  </span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>diff <span class="op">=</span> df[<span class="st">'Spot'</span>].diff()</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>plt.plot(diff)</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'First Differences'</span>)</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Prices'</span>)  </span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Log prices</span></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>log_prices <span class="op">=</span> np.log(df[<span class="st">'Spot'</span>]) </span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>plt.plot(log_prices)</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Log  Levels'</span>)</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Log Prices'</span>) </span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a><span class="co"># Log first diffs  </span></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>log_diff <span class="op">=</span> np.log(df[<span class="st">'Spot'</span>]).diff()</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>plt.plot(log_diff)</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Log First Differences'</span>) </span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Log Prices'</span>)</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a><span class="co">#Engle Granger</span></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a><span class="co"># regression</span></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a><span class="co"># Y_t = a + Bx_t + u_t</span></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="bu">len</span>(df)</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'Spot'</span>]</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> df[<span class="st">'Futures'</span>]</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>reg <span class="op">=</span> stats.linregress(x, y)</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>uhat <span class="op">=</span> y <span class="op">-</span> reg.intercept  <span class="op">-</span> reg.slope <span class="op">*</span> x</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>residuals <span class="op">=</span> pd.Series(uhat)</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> adfuller(uhat)</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'ADF: </span><span class="sc">%f</span><span class="st">   | P Value: </span><span class="sc">%f</span><span class="st">'</span> <span class="op">%</span> (results[<span class="dv">0</span>], results[<span class="dv">1</span>]))</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>residuals.plot(grid <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Residuals"</span>)</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.show()</span></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"As visible from the residuals plot, we can see that the data is relatively stationary, focused pretty tightly on the mean. Because of this mean reversion we can conclude that the residuals are cointegrated by following a constant mean pattern. Mean reversion is visibly prominent in this plot, and we can see a few extreme data points, but it is a tight cointegration."</span>)</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a><span class="co"># minimum variance hedge ratio</span></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a><span class="co"># h* = (p * o_s)/o_f</span></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a><span class="co"># h* = min var hedge ratio</span></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a><span class="co"># p = corr coefficient spot price change futures price change</span></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a><span class="co"># o_f = std dev future</span></span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a><span class="co"># o_s = std dev spot </span></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'WTI-Prices-1992-to-1993.csv'</span>, parse_dates <span class="op">=</span> [<span class="st">'Date'</span>])</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a>spotChanges <span class="op">=</span> df[<span class="st">'Spot'</span>].diff()</span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a>futureChanges <span class="op">=</span> df[<span class="st">'Futures'</span>].diff()</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>ratios <span class="op">=</span> []</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a>days <span class="op">=</span> <span class="dv">60</span></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(days, <span class="bu">len</span>(df)):</span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>   spotWindow <span class="op">=</span> spotChanges.iloc[i <span class="op">-</span> days:i]</span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>   futureWindow <span class="op">=</span> futureChanges.iloc[i <span class="op">-</span> days:i]</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a>   cov <span class="op">=</span> spotWindow.cov(futureWindow)</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a>   var <span class="op">=</span> futureWindow.var()</span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a>   hr <span class="op">=</span> cov <span class="op">/</span> var</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>   ratios.append(hr)</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>hrSeries <span class="op">=</span> pd.Series(ratios, index <span class="op">=</span> df.loc[days:].Date)</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a>hrSeries.plot()</span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Min Var Hedge Ratio"</span>) </span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Date"</span>)</span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Hedge Ratio"</span>)</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"It is visible by the Min Var Hedge Ratio plot that the minimum variance hedge ratio is not very stable as it fluctuates quite a bit over the time series.</span><span class="ch">\n</span><span class="st">The data does seem pretty consistent on the ratio of 1, but we also have large large declines in the middle fo the year 1993.</span><span class="ch">\n</span><span class="st">Because of such large spikes is a little worrisome to be consistent for long periods of time and with such instability there is a lot of risk involved. "</span>)</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Levels
ADF Stat: -0.280351
p_value: 0.928241

First Price Differences
ADF Stat: -22.470295
p_value: 0.000000

Log Prices - Levels
ADF Stat: 0.024364
p_value: 0.960501

Log Prices - Differences
ADF Stat: -22.623511
p_value: 0.000000

Levels: Since the P Value is so high, I conclude that we fail to reject the null hypothesis of a unit root. In other words, the levels in this time series contain a unit root and are non-stationary.


First Price Differences: Since the P Value is 0 we can reject the null hyptothesis and I conclude the First Price Differences do not contain a unit root and are stationary time sets.  


Log Levels: Even after changing to log the P Value stays high, this again means that we can fail to reject the null hyptothesis and I continue to conlude that the log levels containa unit root and are non-stationarity.

  
Log First Differences: P value still stays at 0 meaning we continue to strongly reject the null hypothesis. I also continue to conclude that the log of first differences does not contain a unit root and are stationary time sets.


For time series data it does not suprise me too much, with most time series data it is stochastic, however when we take differences in price levels, because of random walk and mean reversion I expect the difference to all make the data stationary.




TIME SERIES PLOTS:
ADF: -11.993263   | P Value: 0.000000
As visible from the residuals plot, we can see that the data is relatively stationary, focused pretty tightly on the mean. Because of this mean reversion we can conclude that the residuals are cointegrated by following a constant mean pattern. Mean reversion is visibly prominent in this plot, and we can see a few extreme data points, but it is a tight cointegration.
It is visible by the Min Var Hedge Ratio plot that the minimum variance hedge ratio is not very stable as it fluctuates quite a bit over the time series.
The data does seem pretty consistent on the ratio of 1, but we also have large large declines in the middle fo the year 1993.
Because of such large spikes is a little worrisome to be consistent for long periods of time and with such instability there is a lot of risk involved. </code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="midterm_files/figure-html/cell-2-output-2.png" width="585" height="431"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="midterm_files/figure-html/cell-2-output-3.png" width="600" height="431"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="midterm_files/figure-html/cell-2-output-4.png" width="589" height="431"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="midterm_files/figure-html/cell-2-output-5.png" width="608" height="431"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="midterm_files/figure-html/cell-2-output-6.png" width="582" height="431"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="midterm_files/figure-html/cell-2-output-7.png" width="597" height="432"></p>
</div>
</div>
</section>
<section id="q11.-bayesian-futures" class="level4">
<h4 class="anchored" data-anchor-id="q11.-bayesian-futures">Q11. Bayesian Futures</h4>
<blockquote class="blockquote">
<p>The first thing I really got out of Quintana, Carvalho, Scott and Costigliola’s article is that futures markets, while appearing to be giving accurate consistent data, are still beatable, in the fashion of making returns. As stated with the binary bet, mixed in with the bayesian speculation, there is a probabilistic or arbitristic approach that will require other types of models, risk analysis and optimization. It came to my mind the thought by Buchanan in his paper Method, Process, and Austrian Economics, where he states, “..the next steps are not easy. The advances themselves will, of course, be genuine choices in the full [Shackleian] sense. They cannot be predicted. But there is surely some relationship between the objects of attention and the imaginative results that emerge. So long as modern economists devote their considerable intellectual energies, and imaginative skills, to the search for empirically testable regularities in human conduct, they will succeed in extending the scope of applicability for man-as-rat metaphor to describe economic theory.” I feel as that made an impact in my thinking of *beatable” futures markets, because as Buchanan says There is surely some kind of relationship in the catallactic market. Someone out their has a goal in mind that combined with the goals and ingenuity of others, there is a possibility, a binary test, to beat the futures markets and truly understand a perfect risk model. Continued in the Bayesian Futures paper, I come to understand the quantitative framework that the Bayesian approach can bring. With the correct expectations for the models and the risks, an arbitrage opportunity is truly prominent as we test over time and understand to a near perfect understanding of how the market works.</p>
</blockquote>
</section>
<section id="q12.-bollen-and-whaley" class="level4">
<h4 class="anchored" data-anchor-id="q12.-bollen-and-whaley">Q12. Bollen and Whaley</h4>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plot</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> size, log, exp, pi, <span class="bu">sum</span>, diff, array, zeros, diag, mat, asarray, sqrt, copy</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> simulated_supply(params, numObs<span class="op">=</span><span class="dv">252</span>, numReps <span class="op">=</span> <span class="dv">10000</span>): </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    a1 <span class="op">=</span> params[<span class="dv">0</span>]</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    b1 <span class="op">=</span> params[<span class="dv">1</span>]</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    s1 <span class="op">=</span> params[<span class="dv">2</span>]</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    S1 <span class="op">=</span> params[<span class="dv">3</span>]</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    paths <span class="op">=</span> np.empty((numReps, numObs))</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(numReps):</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        paths[i,<span class="dv">0</span>] <span class="op">=</span> np.log(S1)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> np.random.normal(size <span class="op">=</span> numObs)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, numObs):</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>            paths[i, j] <span class="op">=</span> paths[i, j <span class="op">-</span> <span class="dv">1</span>] <span class="op">+</span> a1 <span class="op">*</span> (b1 <span class="op">-</span> exp(paths[i, j <span class="op">-</span> <span class="dv">1</span>])) <span class="op">+</span> z[j] <span class="op">*</span> s1</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> paths</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>alpha_1 <span class="op">=</span> <span class="fl">0.342</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>beta_1 <span class="op">=</span> <span class="fl">0.539</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>sigma_1 <span class="op">=</span> <span class="fl">0.11</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>alpha_2 <span class="op">=</span> <span class="fl">0.391</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>beta_2 <span class="op">=</span> <span class="fl">0.560</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>sigma_2 <span class="op">=</span> <span class="fl">0.116</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="fl">0.705</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>S1 <span class="op">=</span> <span class="fl">0.69</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>oilParams <span class="op">=</span> array([alpha_1, beta_1, sigma_1, S1])</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>gasParams <span class="op">=</span> array([alpha_2, beta_2, sigma_2, S1])</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>numObs <span class="op">=</span> <span class="dv">45</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>numReps <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>paths <span class="op">=</span> simulated_supply(oilParams, numObs, numReps)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.exp(paths[:,<span class="op">-</span><span class="dv">1</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[0.5012471  0.59795549 0.6174155  0.57502181 0.65245003 0.44490897
 0.65004549 0.53514945 0.43398069 0.44028307]</code></pre>
</div>
</div>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>